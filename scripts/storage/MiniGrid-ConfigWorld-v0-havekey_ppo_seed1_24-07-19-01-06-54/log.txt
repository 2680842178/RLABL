discover.py --task-config 1 --discover 0 --algo ppo --env MiniGrid-ConfigWorld-v0-havekey

Namespace(task_config='1', discover=0, algo='ppo', env='MiniGrid-ConfigWorld-v0-havekey', model=None, seed=1, log_interval=1, save_interval=10, procs=1, frames=10000000, AnomalyNN=None, epochs=32, batch_size=128, frames_per_proc=256, discount=0.99, lr=0.0001, gae_lambda=0.95, entropy_coef=0.01, value_loss_coef=0.5, max_grad_norm=0.5, optim_eps=1e-08, optim_alpha=0.99, clip_eps=0.2, recurrence=1, text=False)

Device: cuda

Environments loaded

Training status loaded

Observations preprocessor loaded
Model loaded

ACModel(
  (image_conv): Sequential(
    (0): Conv2d(3, 32, kernel_size=(12, 12), stride=(6, 6))
    (1): ReLU()
    (2): Conv2d(32, 64, kernel_size=(9, 9), stride=(4, 4))
    (3): ReLU()
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))
    (5): ReLU()
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU()
  )
  (actor): Sequential(
    (0): Linear(in_features=2304, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=7, bias=True)
  )
  (critic): Sequential(
    (0): Linear(in_features=2304, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)

Optimizer loaded

U 1 | F 000256 | FPS 0053 | D 4 | Reward:μσmM -0.50 0.50 -1.00 0.00 | policy_loss ['None', 'None', '0.009'] | value_loss ['None', 'None', '0.031']
U 2 | F 000512 | FPS 0063 | D 8 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.053'] | value_loss ['None', 'None', '0.000']
U 3 | F 000768 | FPS 0061 | D 13 | Reward:μσmM 0.24 0.24 0.00 0.47 | policy_loss ['None', 'None', '-0.108'] | value_loss ['None', 'None', '0.010']
U 4 | F 001024 | FPS 0066 | D 17 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.037'] | value_loss ['None', 'None', '0.000']
U 5 | F 001280 | FPS 0069 | D 20 | Reward:μσmM -0.50 0.50 -1.00 0.00 | policy_loss ['None', 'None', '0.011'] | value_loss ['None', 'None', '0.014']
U 6 | F 001536 | FPS 0069 | D 24 | Reward:μσmM -0.50 0.50 -1.00 0.00 | policy_loss ['None', 'None', '0.032'] | value_loss ['None', 'None', '0.014']
U 7 | F 001792 | FPS 0068 | D 28 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.024'] | value_loss ['None', 'None', '0.000']
U 8 | F 002048 | FPS 0062 | D 32 | Reward:μσmM -0.50 0.50 -1.00 0.00 | policy_loss ['None', 'None', '0.031'] | value_loss ['None', 'None', '0.017']
U 9 | F 002304 | FPS 0060 | D 36 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.033'] | value_loss ['None', 'None', '0.000']
U 10 | F 002560 | FPS 0066 | D 40 | Reward:μσmM -0.03 0.78 -1.00 0.90 | policy_loss ['None', 'None', '-0.049'] | value_loss ['None', 'None', '0.030']
Status saved
U 11 | F 002816 | FPS 0065 | D 44 | Reward:μσmM 0.38 0.38 0.00 0.76 | policy_loss ['None', 'None', '-0.096'] | value_loss ['None', 'None', '0.012']
U 12 | F 003072 | FPS 0067 | D 48 | Reward:μσmM -0.27 0.79 -1.00 0.90 | policy_loss ['None', 'None', '-0.021'] | value_loss ['None', 'None', '0.042']
U 13 | F 003328 | FPS 0068 | D 52 | Reward:μσmM 0.62 0.38 0.00 0.98 | policy_loss ['None', 'None', '-0.137'] | value_loss ['None', 'None', '0.028']
U 14 | F 003584 | FPS 0067 | D 56 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.001'] | value_loss ['None', 'None', '0.000']
U 15 | F 003840 | FPS 0060 | D 60 | Reward:μσmM 0.33 0.83 -1.00 0.97 | policy_loss ['None', 'None', '-0.164'] | value_loss ['None', 'None', '0.074']
U 16 | F 004096 | FPS 0066 | D 64 | Reward:μσmM 0.70 0.35 0.00 0.92 | policy_loss ['None', 'None', '-0.142'] | value_loss ['None', 'None', '0.020']
U 17 | F 004352 | FPS 0066 | D 68 | Reward:μσmM 0.86 0.27 0.00 0.98 | policy_loss ['None', 'None', '-0.242'] | value_loss ['None', 'None', '0.017']
U 18 | F 004608 | FPS 0068 | D 72 | Reward:μσmM 0.85 0.28 0.00 0.96 | policy_loss ['None', 'None', '-0.122'] | value_loss ['None', 'None', '0.005']
U 19 | F 004864 | FPS 0066 | D 75 | Reward:μσmM 0.71 0.58 -1.00 0.98 | policy_loss ['None', 'None', '-0.055'] | value_loss ['None', 'None', '0.046']
U 20 | F 005120 | FPS 0066 | D 79 | Reward:μσmM 0.90 0.23 0.00 0.98 | policy_loss ['None', 'None', '-0.073'] | value_loss ['None', 'None', '0.002']
Status saved
U 21 | F 005376 | FPS 0068 | D 83 | Reward:μσmM 0.90 0.23 0.00 0.99 | policy_loss ['None', 'None', '-0.006'] | value_loss ['None', 'None', '0.002']
