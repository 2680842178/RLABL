discover.py --task-config 1 --discover 0 --algo ppo --env MiniGrid-ConfigWorld-v0-havekey

Namespace(task_config='1', discover=0, algo='ppo', env='MiniGrid-ConfigWorld-v0-havekey', model=None, seed=1, log_interval=1, save_interval=10, procs=1, frames=10000000, AnomalyNN=None, epochs=32, batch_size=128, frames_per_proc=256, discount=0.99, lr=0.0001, gae_lambda=0.95, entropy_coef=0.01, value_loss_coef=0.5, max_grad_norm=0.5, optim_eps=1e-08, optim_alpha=0.99, clip_eps=0.2, recurrence=1, text=False)

Device: cuda

Environments loaded

Training status loaded

Observations preprocessor loaded
Model loaded

ACModel(
  (image_conv): Sequential(
    (0): Conv2d(3, 32, kernel_size=(12, 12), stride=(6, 6))
    (1): ReLU()
    (2): Conv2d(32, 64, kernel_size=(9, 9), stride=(4, 4))
    (3): ReLU()
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))
    (5): ReLU()
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU()
  )
  (actor): Sequential(
    (0): Linear(in_features=2304, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=7, bias=True)
  )
  (critic): Sequential(
    (0): Linear(in_features=2304, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)

Optimizer loaded

U 1 | F 000256 | FPS 0046 | D 5 | Reward:μσmM -0.50 0.50 -1.00 0.00 | policy_loss ['None', 'None', '0.008'] | value_loss ['None', 'None', '0.016']
U 2 | F 000512 | FPS 0065 | D 9 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.042'] | value_loss ['None', 'None', '0.000']
U 3 | F 000768 | FPS 0064 | D 13 | Reward:μσmM -0.50 0.50 -1.00 0.00 | policy_loss ['None', 'None', '0.020'] | value_loss ['None', 'None', '0.012']
U 4 | F 001024 | FPS 0063 | D 17 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.041'] | value_loss ['None', 'None', '0.000']
U 5 | F 001280 | FPS 0069 | D 21 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.030'] | value_loss ['None', 'None', '0.000']
U 6 | F 001536 | FPS 0063 | D 25 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.028'] | value_loss ['None', 'None', '0.000']
U 7 | F 001792 | FPS 0066 | D 29 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.022'] | value_loss ['None', 'None', '0.000']
U 8 | F 002048 | FPS 0066 | D 33 | Reward:μσmM -0.50 0.50 -1.00 0.00 | policy_loss ['None', 'None', '0.032'] | value_loss ['None', 'None', '0.020']
U 9 | F 002304 | FPS 0064 | D 37 | Reward:μσmM 0.23 0.23 0.00 0.45 | policy_loss ['None', 'None', '-0.071'] | value_loss ['None', 'None', '0.008']
U 10 | F 002560 | FPS 0063 | D 41 | Reward:μσmM 0.35 0.35 0.00 0.69 | policy_loss ['None', 'None', '-0.074'] | value_loss ['None', 'None', '0.011']
Status saved
U 11 | F 002816 | FPS 0063 | D 45 | Reward:μσmM -0.75 0.43 -1.00 0.00 | policy_loss ['None', 'None', '0.126'] | value_loss ['None', 'None', '0.049']
U 12 | F 003072 | FPS 0069 | D 49 | Reward:μσmM -0.28 0.78 -1.00 0.87 | policy_loss ['None', 'None', '0.055'] | value_loss ['None', 'None', '0.087']
U 13 | F 003328 | FPS 0073 | D 52 | Reward:μσmM -0.35 0.68 -1.00 0.59 | policy_loss ['None', 'None', '0.047'] | value_loss ['None', 'None', '0.052']
U 14 | F 003584 | FPS 0068 | D 56 | Reward:μσmM 0.00 0.00 0.00 0.00 | policy_loss ['None', 'None', '-0.022'] | value_loss ['None', 'None', '0.001']
U 15 | F 003840 | FPS 0070 | D 60 | Reward:μσmM 0.19 0.77 -1.00 0.93 | policy_loss ['None', 'None', '-0.062'] | value_loss ['None', 'None', '0.034']
U 16 | F 004096 | FPS 0067 | D 64 | Reward:μσmM 0.52 0.70 -1.00 0.97 | policy_loss ['None', 'None', '-0.077'] | value_loss ['None', 'None', '0.065']
U 17 | F 004352 | FPS 0068 | D 67 | Reward:μσmM 0.83 0.29 0.00 0.95 | policy_loss ['None', 'None', '-0.224'] | value_loss ['None', 'None', '0.021']
U 18 | F 004608 | FPS 0069 | D 71 | Reward:μσmM 0.80 0.31 0.00 0.97 | policy_loss ['None', 'None', '-0.070'] | value_loss ['None', 'None', '0.006']
U 19 | F 004864 | FPS 0070 | D 75 | Reward:μσmM 0.87 0.26 0.00 0.97 | policy_loss ['None', 'None', '-0.068'] | value_loss ['None', 'None', '0.003']
U 20 | F 005120 | FPS 0069 | D 78 | Reward:μσmM 0.96 0.02 0.91 0.97 | policy_loss ['None', 'None', '-0.040'] | value_loss ['None', 'None', '0.002']
Status saved
U 21 | F 005376 | FPS 0069 | D 82 | Reward:μσmM 0.89 0.25 0.00 0.98 | policy_loss ['None', 'None', '-0.012'] | value_loss ['None', 'None', '0.001']
U 22 | F 005632 | FPS 0069 | D 86 | Reward:μσmM 0.58 0.72 -1.00 0.97 | policy_loss ['None', 'None', '0.169'] | value_loss ['None', 'None', '0.209']
U 23 | F 005888 | FPS 0069 | D 90 | Reward:μσmM 0.81 0.31 0.00 0.96 | policy_loss ['None', 'None', '-0.047'] | value_loss ['None', 'None', '0.005']
U 24 | F 006144 | FPS 0065 | D 94 | Reward:μσmM 0.74 0.33 0.00 0.95 | policy_loss ['None', 'None', '0.006'] | value_loss ['None', 'None', '0.003']
U 25 | F 006400 | FPS 0066 | D 98 | Reward:μσmM 0.83 0.29 0.00 0.98 | policy_loss ['None', 'None', '-0.057'] | value_loss ['None', 'None', '0.004']
U 26 | F 006656 | FPS 0066 | D 102 | Reward:μσmM 0.86 0.27 0.00 0.97 | policy_loss ['None', 'None', '-0.053'] | value_loss ['None', 'None', '0.003']
